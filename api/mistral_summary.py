import os
import requests
import logging
from typing import List

# Configuration du logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# üîß Param√®tres configurables via variables d‚Äôenvironnement
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://ollama:11434/api/generate")
MODEL_NAME = os.getenv("OLLAMA_MODEL", "mistral")
TEMPERATURE = float(os.getenv("OLLAMA_TEMPERATURE", "0.3"))  # Valeur par d√©faut : neutre
TOP_P = float(os.getenv("OLLAMA_TOP_P", "1.0"))               # Valeur par d√©faut : standard

def build_prompt(reviews: List[str], lang: str = "en") -> str:
    text = "\n".join([f"- {r}" for r in reviews])

    if lang == "fr":
        return f"""Tu es un journaliste sp√©cialis√© dans les jeux vid√©o, charg√© d‚Äôanalyser des critiques professionnelles et des retours de joueurs.
√Ä partir des avis disponibles sur Metacritic, tu dois traduire en fran√ßais et r√©sumer fid√®lement les critiques fournies.
Ton objectif est de produire une synth√®se r√©dig√©e, claire, neutre et structur√©e, qui met en √©vidence les points positifs, les points n√©gatifs, ainsi que le ressenti g√©n√©ral exprim√© dans les avis.
N‚Äôajoute aucune information ext√©rieure et ne donne aucune opinion personnelle.
La r√©ponse doit √™tre r√©dig√©e uniquement en fran√ßais, sous forme de texte continu, sans puces, sans num√©rotation, ni formatage sp√©cial.

Avis :
{text}
"""
    else:
        return f"""Here are player reviews about a video game:
{text}

Write a clear and neutral summary that highlights the main strengths, weaknesses, and general feeling around the game.
Do not add personal opinion or external context.
"""

def generate_summary(reviews: List[str], lang: str = "en") -> dict:
    if not reviews:
        raise ValueError("La liste des critiques est vide.")

    prompt = build_prompt(reviews, lang)
    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": TEMPERATURE,
            "top_p": TOP_P
        }
    }

    try:
        logger.info(f"Envoi du prompt √† {OLLAMA_URL} avec temperature={TEMPERATURE}, top_p={TOP_P}")
        response = requests.post(OLLAMA_URL, json=payload, timeout=300)
        response.raise_for_status()
        summary = response.json().get("response", "").strip()
        logger.info("R√©sum√© g√©n√©r√© avec succ√®s.")
        return {
            "summary": summary,
            "model": MODEL_NAME,
            "used_lang": lang,
            "temperature": 0.2,
            "top_p": 1.0
        }
    except requests.RequestException as e:
        logger.error(f"Erreur lors de la g√©n√©ration du r√©sum√© : {e}")
        raise RuntimeError(f"Erreur lors de la g√©n√©ration du r√©sum√© : {e}")
